<!DOCTYPE html>
<html>
<head>
    <title>About Me</title>
    <style>
        div {
        margin-left: 15%;
        margin-right: 15%;
        /*width: 210px;
        height: 130px;
         background:green; */
        border-radius: 13px;
        }
        .sample {
        background-color: green;
        margin-left: 3%;
        }
        .sample1 {
        background-color: yelllow;
        }
        .sample2 {
        background-color: solid green;
        margin-left: -13%;
        }
        .photo{
            /*width:120px;
            height: auto;*/
            margin-right: 20%;
            float: right;
            text-align: right;
        }
        a {
          outline: none;
          text-decoration: none;
          padding: 2px 1px 0;
        }
        
        a:link {
          color: #265301;
        }
        
        a:visited {
          color: #437a16;
        }
        
        a:focus {
          border-bottom: 1px solid;
          background: #bae498;
        }
        
        a:hover {
          border-bottom: 1px solid;
          background: #cdfeaa;
        }
        
        a:active {
          background: #265301;
          color: #cdfeaa;
        }
        </style>
</head>
<body>
    <div class="photo">
        <img src="./cv.jpg" alt="Personal photo", width=120px,  height=auto>
    </div>
<div>
    <h1>Yuhao Zhang</h1>
    <h2>Natural language processing lab, Northeastern university, Shenyang, China</h2>
    <p> PhD student &nbsp;&nbsp;&nbsp;&nbsp; <a href="https://scholar.google.com/citations?hl=zh-CN&user=p3Om2OcAAAAJ">Google scholar</a> </br> Contact me: yoohao.zhang@gmail.com</p> 
    <p> Research interests: <b>Speech translation</b>, <b>Machine translation</b> and <b>Multi-task learning</b>.  </p>
    <p> Severed as the reviewer of NeurIPS, ACL, AAAI, EMNLP, ICASSP and other conferences for many times.</p>
    <h2>Education experiments</h2>
    <dl>
        <dt>2020.9 - now</dt>
        <dd>Computer sinence and techolegy, PhD student at Northeastern university </dd>
        <dd>NEU NLP lab, supervisors：Prof. XIAO Tong and Porf. ZHU Jingbo</dd>
        <dd>Ph.D. project: Unified Cross-Modal Modeling for End-to-End Speech Translation</dd>
        <dt>2018.9-2020.7 </dt>
        <dd>Computer software and theory, Master student at Northeastern university</dd>
        <dd>NEU NLP lab, supervisor：Prof. XIAO Tong</dd>
        <dd>Thesis title: Research on Performance and Inference Speed Improvement for Multilingual Neural Machine Translation</dd>
        <dt>2014.9-2018.7  </dt>
        <dd>Computer sinence and techolegy, Bachelor student at Northeastern university</dd>
        <dd>Thesis title: Fast Decoding Method and Implementation for Neural Machine Translation</dd>
      </dl>
 
</div>

<div>
    <h2>Publications</h2>
    1. <a href="https://arxiv.org/pdf/2312.10952.pdf", target="_blank">Soft Alignment of Modality Space for End-to-end Speech Translation.</a> <b>Yuhao Zhang</b>, Kaiqi Kou, Bei Li, Chen Xu, Chunliang Zhang, Tong Xiao, Jingbo Zhu. <b>ICASSP2024</b>. </br>
    2. <a href="https://arxiv.org/pdf/2311.03810.pdf", target="_blank">Rethinking and Improving Multi-task Learning for End-to-end Speech Translation.</a> <b>Yuhao Zhang</b>, Chen Xu, Bei Li, Hao Chen, Tong Xiao, Chunliang Zhang, and Jingbo Zhu. <b>EMNLP2023</b>. </br>
    3. <a href="https://arxiv.org/pdf/2212.01778.pdf", target="_blank">Improving End-to-end Speech Translation by Leveraging Auxiliary Speech and Text Data.</a> <b>Yuhao Zhang</b>, Chen Xu, Bojie Hu, Chunliang Zhang, Tong Xiao, Jingbo Zhu. <b>AAAI2023</b>. </br>
    4. <a href="https://www.isca-archive.org/interspeech_2023/zhang23u_interspeech.pdf", target="_blank">Information Magnitude Based Dynamic Sub-sampling for Speech-to-text.</a> <b>Yuhao Zhang</b>, Chenghao Gao, Kaiqi Kou, Chen Xu, Tong Xiao, Jingbo Zhu. <b>INTERSPEECH2023</b>. </br>
    5. <a href="https://aclanthology.org/2022.iwslt-1.19.pdf", target="_blank">The NiuTrans’s Submission to the IWSLT22 English-to-Chinese Offline Speech Translation Task.</a> <b>Yuhao Zhang</b>, Canan Huang, Chen Xu, Xiaoqian Liu, Bei Li, Anxiang Ma, Tong Xiao, Jingbo Zhu. <b>IWSLT2022</b>. </br>
    6. <a href="https://aclanthology.org/2020.wmt-1.37.pdf", target="_blank">The NiuTrans Machine Translation Systems for WMT20.</a> <b>Yuhao Zhang</b>, Ziyang Wang, Runzhe Cao.et.al. <b>WMT2020</b>. </br>
    7. <a href="https://jxmu.xmu.edu.cn/#/digest?ArticleID=4390", target="_blank">Inference acceleration method of neural machine translation system based on coarse-to-fine.</a> <b>Yuhao Zhang</b>, Nuo Xu, Yinqiao Li, Tong Xiao, Jingbo Zhu. <b>CCMT2019</b>. </br>
    8. <a href="https://arxiv.org/pdf/2309.12234.pdf", target="_blank">Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition.</a> Chen Xu, Xiaoqian Liu, Erfeng He, <b>Yuhao Zhang</b>, Qianqian Dong, Tong Xiao, Jingbo Zhu, Dapeng Man, Wu Yang. <b>ICASSP2024</b>. </br>
    9. <a href="https://arxiv.org/pdf/2305.17356.pdf", target="_blank">Bridging the Granularity Gap for Acoustic Modeling.</a> Chen Xu, <b>Yuhao Zhang</b>, Chengbo Jiao, Xiaoqian Liu, Chi Hu, Xin Zeng, Tong Xiao, Anxiang Ma, Huizhen Wang, JingBo Zhu. <b>ACL2023</b> findings.</br>
    10. <a href="https://aclanthology.org/2023.ccl-1.41.pdf", target="_blank">An End-to-End Automatic Speech Recognition Method Based on Multiscale Modeling.</a> Chen Hao, Runlai Zhang, <b>Yuhao Zhang</b>, Chenghao Gao, Chen Xu, Anxiang Ma, Tong Xiao, Jingbo Zhu. <b>CCL2023</b>. </br>
    11. <a href="https://arxiv.org/pdf/2105.05752.pdf", target="_blank">Stacked Acoustic-and-Textual Encoding: Integrating the Pre-trained Models into Speech Translation Encoders.</a> Chen Xu, Bojie Hu, Yanyang Li, <b>Yuhao Zhang</b>, Shen Huang, Qi Ju, Tong Xiao, Jingbo Zhu. <b>ACL2021</b>. </br>
    12. <a href="https://aclanthology.org/2020.acl-main.592.pdf", target="_blank">Learning Architectures from an Extended Search Space for Language Modeling.</a> Yinqiao Li, Chi Hu, <b>Yuhao Zhang</b>, Nuo Xu, Yufan Jiang, Tong Xiao, Jingbo Zhu, Tongran Liu, Changliang Li. <b>ACL2020</b>. </br>
    13. <a href="https://aclanthology.org/2023.acl-long.744.pdf", target="_blank">CTC-based Non-autoregressive Speech Translation.</a> Chen Xu, Xiaoqian Liu, Xiaowen Liu, Qingxuan Sun, <b>Yuhao Zhang</b>, Murun Yang, Qianqian Dong, Tom Ko, Mingxuan Wang, Tong Xiao, Anxiang Ma, Jingbo Zhu. <b>ACL2023</b>.</br>
    14. <a href="https://aclanthology.org/2023.iwslt-1.17.pdf", target="_blank">The NiuTrans End-to-End Speech Translation System for IWSLT23 English-to-Chinese Offline Task.</a> Yuchen Han, Xiaoqian Liu, Hao Chen, <b>Yuhao Zhang</b>, Chen Xu, Tong Xiao, Jingbo Zhu. <b>IWSLT2023</b>.</br>
    15. <a href="https://aclanthology.org/W19-5325.pdf", target="_blank">The NiuTrans machine translation systems for WMT19.</a> Bei Li, Yinqiao Li, Chen Xu, Ye Lin, Jiqiang Liu, Hui Liu, Ziyang Wang, <b>Yuhao Zhang</b>, et al. <b>WMT2019</b>.</br>
</div>

<div>
    <h2>Projects </h2>
    <table>
    <tr><td><b>An end-to-end speech-to-text toolkit, NiuTrans.ST</b></td><td>2023.09- ······</td></tr>
    <tr><td>The toolkit can achieve ASR, MT and ST three tasks. This toolkit is based on NiuTensor library and our goal is to achieve a high speed inference framework for speech-to-text generation.</td></tr>
    <tr><td>Project website: <a href="https://github.com/xiaozhang521/NiuTrans.ST">https://github.com/xiaozhang521/NiuTrans.ST</a></td></tr>
    <tr><td><b>Soft alignment method for end-to-end speech translation </b> (ICASSP2024)</td>   <td>2023.05-2023.09 </td></tr>
    <tr><td>In response to the challenge of inconsistent representation between speech and text modalities, we propose a soft alignment methodology within the representation space, leveraging an adversarial training strategy. This approach not only attains advanced performance in speech translation tasks but also accomplishes speech recognition, text translation, and speech translation tasks with one model. The achieved performance closely parallels that of the individual models.</td></tr>

    <tr><td><b>An End-to-End Automatic Speech Recognition Method Based on Multi-scale Modeling</b> (CCL2023)</td>   <td>2023.02-2023.05 </td></tr>
    <tr><td>We designed a multi-scale modeling method to align the original audio features to phonemes, characters and sub-words step by step, and then design a gated network to integrate multi-scale features. This method can effectively alleviate the modal gap caused by length inconsistency.</td></tr>
    
    <tr><td><b>End-to-end Speech Translation Evaluation</b> (IWSLT2023)</td>        <td>2023.02-2023.04</td> </tr>
    <tr><td>We participated in the IWSLT 2023 English to Chinese offline end-to-end speech translation (constrained data) track. We mainly implement the multi-task leaning, multi-scale modeling, stacked acoustic-and-textual encoding and VAD based on SHAS. Our system ranked 1st in this track. </td></tr>

    <tr><td><b>Information Magnitude Based Dynamic Sub-sampling for Speech-to-text </b> (Interspeech2023) </td> <td>   2022.05-2023.01</td> </tr>
    <tr><td> We design a dynamic down-sampling strategy for audio frames to solve the problem of long speech sequences. We use the Gaussian mixture model to distinguish the magnitude of each frame and then dynamically design the sampling stride according to the order of magnitude. For speech translation and speech recognition tasks, this method can achieve a larger compression ratio without losing performance compared to static down-sampling.</td></tr>

    <tr><td><b>Rethinking and Improving Multi-task Learning for End-to-end Speech Translation</b> (EMNLP2023)  </td>                   <td>2022.06-2023.06 </td></tr>
    <tr><td>Based on the quantitative analysis of the effect and time of the interaction between speech and other auxiliary tasks, it is found that the length gap between speech and text modalities hinders the learning effect of the alignment method. Additionally, the difference between speech and text representations is still significant. In light of these phenomena, we design the lookback mechanism and the local-to-global training method to improve performance and achieve the state-of-the-art (SOTA) performance under limited data.</td></tr>

    <tr><td><b>End-to-end Speech Translation Evaluation</b> (IWSLT2022) </td>                        <td>   2022.02-2022.05 </td></tr>
    <tr><td>We participated in the offline end-to-end English-Chinese speech translation task, mainly using the decoupling pre-training method, multi-stage pre-training method, and multi-view fusion method. We further combined the strategies of VAD consistency training and model ensemble. </td></tr>

    <tr><td><b>Improving end-to-end speech translation by leveraging auxiliary speech and text data</b> (AAAI2023) </td>                      <td>  2021.03-2021.11 </td></tr>
    <tr><td>In order to address the problem of data scarcity for end-to-end speech translation training, we propose a multi-stage pre-training strategy to build speech translation system. Our method can use all types of unlabeled and labeled text data, as well as speech data, which achieves a new state-of-the-art performance. The work was partially completed during the internship at Information Security Department of Tencent.</td></tr>

    <tr><td><b>Stacked acoustic-and-textual encoding: Integrating the pre-trained models into speech translation encoders</b> (ACL2021)</td>                             <td> 2020.09-2021.01 </td></tr>
    <tr><td>Aiming to address the issue of unstable training in the end-to-end speech translation model, we propose a decoupling pre-training method to separately pre-train the speech recognition model and the text translation model. Subsequently, an adapter is employed to facilitate the integration of the two. We first achieve performance where the end-to-end system outperforms the cascade system under conditions of limited data. </td></tr>

    <tr><td><b>Tensor computing library towards offline device</b></td>                             <td> 2020.11-2020.12 </td></tr>
    <tr><td>We use the OpenCL interface in the ARM Computing Library to rewrite the operations in NiuTensor and run them on the Mali architecture chip. The system has been applied to the Translation Pen Scanner. </td></tr>

    <tr><td><b>Quantifying Transfer Learning for Multilingual Neural Machine Translation</b> (Under review) </td>           <td> 2020.06-2021.03 </td></tr>
    <tr><td>We conduct a quantitative analysis of the interference and transfer of rich resources and low resources in the multilingual translation model, and we find that the transfer process mainly occurs in the early training stage, while the interference is primarily in the later stage.</td> </tr>

    <tr><td><b>Machine Translation Evaluation</b> (WMT2020)</td>                          <td>2020.03-2020.05 </td></tr>
    <tr><td>We participate in three rich resource tasks (English to/from Japanese, English to Chinese) and two low resource tasks (Tamil to English and Inuktitut to English). Our training strategies include using a multi-language model, a large-capacity model, iterative fine-tuning, generating pseudo-data by Top-p sampling, domain adaptation with a pre-trained language model, and so on. Among them, English to/from Japanese ranks first in automatic evaluation; English to Japanese and Inuktitut to English win first place in manual evaluation.  </td></tr>

    <tr><td><b>Learning architectures from an extended search space for language modeling</b> (ACL2020)</td>                                <td>2019.10-2019.12 </td></tr>
    <tr><td>We apply the neural structure search method to the neural machine translation task. Initially, we use the differentiable method (e.g., DARTS) to search for a structure between the inner-CELL and intra-CELL on the language model task. Subsequently, we apply this structure to the task of neural machine translation. The experimental results show that the searched structure improves the performance of the IWSLT English-to-Vietnamese tasks. </td></tr>

    <tr><td><b>Inference acceleration method of neural machine translation system based on coarse-to-fine</b> (CCMT2019) </td>                   <td>2019.06-2019.08 </td></tr>
    <tr><td>We accelerate the attention operation in the inference of the Transformer model. We utilize the attention distribution of each layer in the model and calculate its information entropy as the amount of information contained in each layer. We found that the amount of information in each layer is different, but the amount of calculation is consistent. Therefore, we design a coarse-to-fine method to compress the parameters of attention calculation and improve the decoding speed by about 10% without performance degradation.</td></tr>
    
    <tr><td><b>Machine Translation Evaluation</b> (WMT2019)</td>                         <td>2019.02-2019.04 </td></tr>
    <tr><td>We participated in the Gujarati-to-English translation task, primarily using transfer learning, linguistic prior knowledge, back-translation with diversity, ensemble search, re-ranking based on multi-feature, and the DLCL deep network. Our system ranked first in automatic evaluation and manual evaluation.</td></tr>

    <tr><td><b>NiuTensor Deep Learning Open Source Computing Library</b></td>                    <td>2018.1- ······ </td></tr>
    <tr><td> We have developed an efficient tensor computing library (similar to TensorFlow or PyTorch), named  NiuTensor which is based on C++ and CUDA. Its main features are as follows: 1. Developlow-level high-efficiency CUDA operators; 2. Support speech-to-text tasks and text generation tasks; 3. Support Mobile device; 4. Optimize neural machine translation operation inference (kernel fusion, high concurrency algorithm based on GPU). The project has been applied to the online system of NiuTrans. </td></tr>
    <tr><td>Project website: <a href="https://github.com/NiuTrans/NiuTensor">https://github.com/NiuTrans/NiuTensor</a></td></tr>
    </table>   
</div>

<div>
<h2>Awards</h2>
<ul>
    <li>1st, IWSLT23 English to Chinese Offline End-to-End speech translation track (Constrained data).</li>
    <li>3rd, IWSLT22 English to Chinese Offline End-to-End speech translation track.</li>
    <li>1st, WMT20 Japanese to/from English news translation track. </li>
    <li>1st, WMT20 Inuktitut to English news translation track (Human evaluation). </li>
    <li>1st, WMT19 Gujarati to English news translation track. </li>
    <li>Outstanding doctoral candidate. Awarded by Northeastern university.</li>
    <li>Best poster presentation award. Awarded by CCL2023.</li>
    <li>Best Chinese paper award (Honorable Mentions). Awarded by CCMT2019.</li>
    <li>Outstanding graduation thesis (1st). Awarded by School of Computer Science and Technology, Northeastern university.</li>
</ul>

</div>
<p align=center><a href="./index-Chinese.html">中文</a></p>
</body>
</html>